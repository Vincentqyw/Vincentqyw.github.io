<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/realcat-apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/realcat-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/realcat-32x32.png">
  <link rel="mask-icon" href="/images/realcat-safari-pinned-tab.svg" color="#222">
  <meta name="google-site-verification" content="u46QTaG_Dv3OZLpOBKYtqyuiNtIdnhSG5ASKoNvGBCM">
  <meta name="baidu-site-verification" content="MtcbwE45ft">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.vincentqin.tech","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.13.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"show_result":true,"style":"flat"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":"waline","storage":true,"lazyload":true,"nav":null,"activeClass":"waline"},"stickytabs":true,"motion":{"enable":false,"async":true,"transition":{"post_block":"fadeIn","post_header":"fadeIn","post_body":"fadeIn","coll_header":"fadeIn","sidebar":"fadeIn"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="ETHZ ASL与Magicleap联名之作，CVPR 2020 Oral（论文见文末），一作是来自ETHZ的实习生，二作是当年CVPR2018 SuperPoint的作者Daniel DeTone。Sarlin小伙之前在MagicLeap实习，在ETHZ（苏黎世联邦理工） ASL 完成硕士，目前在 ETHZ CVG就读博士，不是TUM（慕尼黑工业大学）的CVG。">
<meta property="og:type" content="article">
<meta property="og:title" content="📝笔记：SuperGlue:Learning Feature Matching with Graph Neural Networks论文阅读">
<meta property="og:url" content="https://www.vincentqin.tech/posts/superglue/index.html">
<meta property="og:site_name" content="RealCat">
<meta property="og:description" content="ETHZ ASL与Magicleap联名之作，CVPR 2020 Oral（论文见文末），一作是来自ETHZ的实习生，二作是当年CVPR2018 SuperPoint的作者Daniel DeTone。Sarlin小伙之前在MagicLeap实习，在ETHZ（苏黎世联邦理工） ASL 完成硕士，目前在 ETHZ CVG就读博士，不是TUM（慕尼黑工业大学）的CVG。">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-04-17T17:21:56.000Z">
<meta property="article:modified_time" content="2022-05-17T16:36:10.705Z">
<meta property="article:author" content="Vincent Qin">
<meta property="article:tag" content="SLAM">
<meta property="article:tag" content="特征提取">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="笔记">
<meta property="article:tag" content="论文">
<meta property="article:tag" content="SuperGlue">
<meta property="article:tag" content="MagicLeap">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://www.vincentqin.tech/posts/superglue/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://www.vincentqin.tech/posts/superglue/","path":"posts/superglue/","title":"📝笔记：SuperGlue:Learning Feature Matching with Graph Neural Networks论文阅读"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>📝笔记：SuperGlue:Learning Feature Matching with Graph Neural Networks论文阅读 | RealCat</title>
  
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-97856334-1","only_pageview":true}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>





<link rel="dns-prefetch" href="https://comments.vincentqin.tech">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">RealCat</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Turn on, Tune in, Drop out</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">76</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">14</span></a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">111</span></a></li><li class="menu-item menu-item-collections"><a href="/collections" rel="section"><i class="fa fa-diamond fa-fw"></i>Collections</a></li><li class="menu-item menu-item-guest_comments"><a href="/guestbook" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-number">1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="nav-number">2.</span> <span class="nav-text">相关工作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B1%80%E9%83%A8%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D"><span class="nav-number">2.1.</span> <span class="nav-text">局部特征匹配</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%8C%B9%E9%85%8D"><span class="nav-number">2.2.</span> <span class="nav-text">图匹配</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E7%82%B9%E4%BA%91%E5%8C%B9%E9%85%8D"><span class="nav-number">2.3.</span> <span class="nav-text">深度点云匹配</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A1%86%E6%9E%B6%E4%BB%A5%E5%8F%8A%E5%8E%9F%E7%90%86"><span class="nav-number">3.</span> <span class="nav-text">框架以及原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%AC%E5%BC%8F%E5%8C%96"><span class="nav-number">3.1.</span> <span class="nav-text">公式化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9Bgnn"><span class="nav-number">3.2.</span> <span class="nav-text">注意力GNN</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E7%82%B9encode"><span class="nav-number">3.2.1.</span> <span class="nav-text">特征点Encode</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E5%B1%82gnn"><span class="nav-number">3.2.2.</span> <span class="nav-text">多层GNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#attentional-aggregation"><span class="nav-number">3.2.3.</span> <span class="nav-text">Attentional Aggregation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8C%B9%E9%85%8D%E5%B1%82optimal-matching-layer"><span class="nav-number">3.3.</span> <span class="nav-text">匹配层（Optimal matching
layer）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8C%B9%E9%85%8D%E5%BE%97%E5%88%86%E9%A2%84%E6%B5%8B"><span class="nav-number">3.3.1.</span> <span class="nav-text">匹配得分预测</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%81%AE%E6%8C%A1%E4%BB%A5%E5%8F%8A%E5%8F%AF%E8%A7%81%E6%80%A7"><span class="nav-number">3.3.2.</span> <span class="nav-text">遮挡以及可见性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#sinkhorn-algorithm"><span class="nav-number">3.3.3.</span> <span class="nav-text">Sinkhorn Algorithm</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#loss"><span class="nav-number">3.4.</span> <span class="nav-text">Loss</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C"><span class="nav-number">4.</span> <span class="nav-text">实验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%95%E5%BA%94%E7%9F%A9%E9%98%B5%E4%BC%B0%E8%AE%A1"><span class="nav-number">4.1.</span> <span class="nav-text">单应矩阵估计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%A4%E5%86%85%E5%A4%96%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1"><span class="nav-number">4.2.</span> <span class="nav-text">室内外位姿估计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E8%80%97%E6%97%B6"><span class="nav-number">4.3.</span> <span class="nav-text">网络耗时</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9B%B4%E5%A4%9A%E5%8C%B9%E9%85%8D%E7%BB%93%E6%9E%9C"><span class="nav-number">4.4.</span> <span class="nav-text">更多匹配结果</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%93%E8%AE%BA"><span class="nav-number">5.</span> <span class="nav-text">结论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%94%B9%E8%BF%9B%E7%82%B9-update-2022.05.17"><span class="nav-number">6.</span> <span class="nav-text">改进点 (Update: 2022.05.17)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">7.</span> <span class="nav-text">参考</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Vincent Qin"
      src="https://vincentqin.gitee.io/images/qin_small.png">
  <p class="site-author-name" itemprop="name">Vincent Qin</p>
  <div class="site-description" itemprop="description">Keep Your Curiosity</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">76</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">111</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Vincentqyw" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Vincentqyw" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:realcat@126.com" title="Email → mailto:realcat@126.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>Email</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://vincentqin.gitee.io/images/qrcode_realcat.jpg" title="Wechat → https:&#x2F;&#x2F;vincentqin.gitee.io&#x2F;images&#x2F;qrcode_realcat.jpg" rel="noopener" target="_blank"><i class="fab fa-weixin fa-fw"></i>Wechat</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/i_vincent/activities" title="Zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;i_vincent&#x2F;activities" rel="noopener" target="_blank"><i class="fab fa-quora fa-fw"></i>Zhihu</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/AlphaRealcat" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;AlphaRealcat" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/18136563" title="Bilibili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;18136563" rel="noopener" target="_blank"><i class="fa fa-video-camera fa-fw"></i>Bilibili</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://bafybeic2jt62kpyh6cz2g4ngxs4kazojfw3dhx53mco3wc6f56dejty4xm.ipfs.infura-ipfs.io/" title="Web3.0 → https:&#x2F;&#x2F;bafybeic2jt62kpyh6cz2g4ngxs4kazojfw3dhx53mco3wc6f56dejty4xm.ipfs.infura-ipfs.io" rel="noopener" target="_blank"><i class="link fa-fw"></i>Web3.0</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-dashboard"></i>
      Scholar
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://xxx.itp.ac.cn/" title="http:&#x2F;&#x2F;xxx.itp.ac.cn" rel="noopener" target="_blank">Arxiv-Mirror</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://arxiv-sanity.com/" title="http:&#x2F;&#x2F;arxiv-sanity.com&#x2F;" rel="noopener" target="_blank">Arxiv-sanity</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://openaccess.thecvf.com/menu.py" title="http:&#x2F;&#x2F;openaccess.thecvf.com&#x2F;menu.py" rel="noopener" target="_blank">CVF</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://paperswithcode.com/sota" title="https:&#x2F;&#x2F;paperswithcode.com&#x2F;sota" rel="noopener" target="_blank">Paper&Code</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://scihub.wikicn.top/" title="https:&#x2F;&#x2F;scihub.wikicn.top&#x2F;" rel="noopener" target="_blank">Scihub</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://ras.papercept.net/conferences/scripts/start.pl" title="http:&#x2F;&#x2F;ras.papercept.net&#x2F;conferences&#x2F;scripts&#x2F;start.pl" rel="noopener" target="_blank">RAS</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://openreview.net/" title="https:&#x2F;&#x2F;openreview.net&#x2F;" rel="noopener" target="_blank">OpenReview</a>
        </li>
    </ul>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-battery-three-quarters fa-fw"></i>
      Friends Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.wangpengan.com/" title="http:&#x2F;&#x2F;www.wangpengan.com&#x2F;" rel="noopener" target="_blank">Tensorboy</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://simtalk.cn/" title="http:&#x2F;&#x2F;simtalk.cn&#x2F;" rel="noopener" target="_blank">Simshang</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://sttomato.github.io/" title="https:&#x2F;&#x2F;sttomato.github.io" rel="noopener" target="_blank">Tomato</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://dfine.tech/" title="http:&#x2F;&#x2F;dfine.tech&#x2F;" rel="noopener" target="_blank">Newdee</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://cs-people.bu.edu/yfhu/" title="http:&#x2F;&#x2F;cs-people.bu.edu&#x2F;yfhu&#x2F;" rel="noopener" target="_blank">WhoIf</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://yulunzhang.com/" title="http:&#x2F;&#x2F;yulunzhang.com&#x2F;" rel="noopener" target="_blank">Yulun</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://sanglongbest.github.io/" title="https:&#x2F;&#x2F;sanglongbest.github.io&#x2F;" rel="noopener" target="_blank">YangLiu</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.erenship.com/" title="https:&#x2F;&#x2F;www.erenship.com&#x2F;" rel="noopener" target="_blank">Eren</a>
        </li>
    </ul>
  </div>

  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-briefcase"></i>
      Common Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://comments.vincentqin.tech/ui" title="https:&#x2F;&#x2F;comments.vincentqin.tech&#x2F;ui" rel="noopener" target="_blank">Comments</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://gitee.com/vincentqin/vincentqin" title="https:&#x2F;&#x2F;gitee.com&#x2F;vincentqin&#x2F;vincentqin" rel="noopener" target="_blank">Source</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.notion.so/realcat" title="https:&#x2F;&#x2F;www.notion.so&#x2F;realcat" rel="noopener" target="_blank">Notion</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.matrixcalculus.org/" title="http:&#x2F;&#x2F;www.matrixcalculus.org&#x2F;" rel="noopener" target="_blank">Calculus</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://emojipedia.org/" title="https:&#x2F;&#x2F;emojipedia.org&#x2F;" rel="noopener" target="_blank">Emoji</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://unstoppabledomains.com/" title="https:&#x2F;&#x2F;unstoppabledomains.com&#x2F;" rel="noopener" target="_blank">UD</a>
        </li>
    </ul>
  </div>




        </div>

      <div class="wechat_QR_code">
      <!-- 二维码 -->
      <img src ="https://vincentqin.tech/blog-resources/qrcode_realcat.jpg">
      <span>Follow Me on Wechat</span>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://www.vincentqin.tech/posts/superglue/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://vincentqin.gitee.io/images/qin_small.png">
      <meta itemprop="name" content="Vincent Qin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RealCat">
      <meta itemprop="description" content="Keep Your Curiosity">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="📝笔记：SuperGlue:Learning Feature Matching with Graph Neural Networks论文阅读 | RealCat">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          📝笔记：SuperGlue:Learning Feature Matching with Graph Neural Networks论文阅读
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-04-18 01:21:56" itemprop="dateCreated datePublished" datetime="2020-04-18T01:21:56+08:00">2020-04-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-05-18 00:36:10" itemprop="dateModified" datetime="2022-05-18T00:36:10+08:00">2022-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Image-Matching/" itemprop="url" rel="index"><span itemprop="name">Image Matching</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline: </span>
  
    <a title="waline" href="/posts/superglue/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/posts/superglue/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-item" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="waline-pageview-count" data-path="/posts/superglue/"></span>
    </span>
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <script src="/assets/js/DPlayer.min.js"> </script><div class="note default"><p>ETHZ ASL与Magicleap联名之作，CVPR 2020
Oral（论文见文末），一作是来自ETHZ的实习生，二作是当年CVPR2018
SuperPoint的作者Daniel
DeTone。Sarlin小伙之前在MagicLeap实习，在ETHZ（苏黎世联邦理工） ASL
完成硕士，目前在 ETHZ CVG就读博士，不是TUM（慕尼黑工业大学）的CVG。</p>
<!-- ![](/posts/superglue/freiburg_matches.gif) -->
</div>
<p><img data-src="https://vincentqin.gitee.io/posts/superglue/freiburg_matches.gif" /></p>
<span id="more"></span>
<p>注：</p>
<ol type="1">
<li>SuperPoint参见另外一篇文章<a
href="https://www.vincentqin.tech/posts/superpoint/">《SuperPoint:
Self-Supervised Interest Point Detection and Description》</a>，<a
target="_blank" rel="noopener" href="https://vincentqin.gitee.io/posts/superpoint/">备用链接</a>。</li>
<li>后文中反复提到的self-attention/cross-attention，我暂时翻译成自我注意力/交叉注意力。</li>
<li>本人知识水平有限，如有错误请在评论区指出。当然，没有问题也可刷刷评论。</li>
</ol>
<p>下面是一作Daniel DeTone关于SuperPoint的讲解(需要科学上网)。</p>
<iframe width="1283" height="731" src="https://www.youtube.com/embed/95Eysm0IeB0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<h2 id="摘要">摘要</h2>
<p>本文提出了一种能够同时进行特征匹配以及滤除外点的网络。其中特征匹配是通过求解可微分最优化转移问题（
optimal transport
problem）来解决；本文基于注意力机制提出了一种将2D特征点以及聚合机制，这使得SuperGlue能够同时感知潜在的3D场景以及进行特征匹配。该算法与传统的，手工设计的特征相比，能够在室内外环境中位姿估计任务中取得最好的结果，该网络能够在GPU上达到实时，预期能够集成到sfm以及slam算法中。</p>
<figure>
<img data-src="https://vincentqin.tech/blog-resources/superglue/superglue_front.png"
alt="superglue_front" />
<figcaption aria-hidden="true">superglue_front</figcaption>
</figure>
<p>SuperGlue是一种特征匹配网络，它的输入是2张图像中特征点以及描述子（手工特征或者深度学习特征均可），输出是图像特征之间的匹配关系。</p>
<p>作者认为学习特征匹配可以被视为找到两簇点的局部分配关系。作者受到了Transformer的启发，同时将self-和cross-attention利用特征点位置以及其视觉外观进行匹配。</p>
<h2 id="相关工作">相关工作</h2>
<h3 id="局部特征匹配">局部特征匹配</h3>
<p><img data-src="https://vincentqin.tech/blog-resources/superglue/superglue_pre-1.png" />
传统的特征可分5步走：1)提取特征点；2)计算描述子；3)最近邻匹配；4)滤除外点；5)求解几何约束；其中滤除外点一步包括点方法有：计算最优次优比，RANSAC，交叉验证以及neighborhood
consensus。</p>
<p>最近的一些工作主要集中在设计特异性更好的稀疏特征上，而它们的匹配算法仍然依赖于NN等策略：在做匹配时并没有考虑特征的结构相似性以及外观相似性。</p>
<h3 id="图匹配">图匹配</h3>
<p>这类方法将特征的匹配问题描述成“quadratic assignment
problems”，这是一个NP-hard问题，求解这类问题需要复杂不切实际的算子。后来的研究者将这个问题化简成“linear
assignment
problems”，但仅仅用了一个浅层模型，相比之下SuperGlue利用深度神经网络构建了一种合适的代价进行求解。此处需要说明的是图匹配问题可以认为是一种“<em>optimal
transport</em>”问题，<strong>它是一种有效但简单的近似解的广义线性分配，即Sinkhorn算法</strong>。</p>
<h3 id="深度点云匹配">深度点云匹配</h3>
<p>点云匹配的目的是通过在元素之间聚集信息来设计置换等价或不变函数。一些算法同等的对待这些元素，还有一些算法主要关注于元素的局部坐标或者特征空间。注意力机制可以通过关注特定的元素和属性来实现全局以及依赖于数据的局部聚合，因而更加全面和灵活。SuperGlue借鉴了这种注意力机制。</p>
<h2 id="框架以及原理">框架以及原理</h2>
<p>特征匹配必须满足的硬性要求是：</p>
<blockquote>
<p>i)至多有1个匹配点；ii)有些点由于遮挡等原因并没有匹配点。</p>
</blockquote>
<p>一个成熟的特征匹配模型应该做到：既能够找到特征之间的正确匹配，又可以鉴别错误匹配。</p>
<figure>
<img data-src="https://vincentqin.tech/blog-resources/superglue/superglue_arch.png"
alt="superglue_arch" />
<figcaption aria-hidden="true">superglue_arch</figcaption>
</figure>
<p>整个框架由两个主要模块组成：注意力GNN以及最优匹配层。其中注意力GNN将特征点以及描述子编码成为一个向量（该向量可以理解为特征匹配向量），随后利用自我注意力以及交叉注意力来回增强（重复<span
class="math inline">\(L\)</span>次）这个向量<span
class="math inline">\(\mathbf{f}\)</span>的特征匹配性能；随后进入最优匹配层，通过计算特征匹配向量的内积得到匹配度得分矩阵，然后通过Sinkhorn算法（迭代<span
class="math inline">\(T\)</span>次）解算出最优特征分配矩阵。</p>
<h3 id="公式化">公式化</h3>
<p><img data-src="https://vincentqin.tech/blog-resources/superglue/superglue_problem-definition.png" />
该部分对特征匹配问题建模。给定两张图片<span
class="math inline">\(A,B\)</span>，每张图片上都有特征点位置<span
class="math inline">\(\mathbf{p}\)</span>以及对应的描述子<span
class="math inline">\(\mathbf{d}\)</span>，所以我们经常用<span
class="math inline">\((\mathbf{p},\mathbf{d})\)</span>来表示图像特征。第<span
class="math inline">\(i\)</span>个特征可以表示为<span
class="math inline">\(\mathbf{p}_i:=(x,y,c)\)</span>，其中<span
class="math inline">\(c\)</span>表示特征点提取置信度，<span
class="math inline">\((x,y)\)</span>表示特征坐标；描述子可以表示为<span
class="math inline">\(\mathbf{d}_i \in
\mathbb{R}^{D}\)</span>，其中<span
class="math inline">\(D\)</span>表示特征维度，这里的特征可以是CNN特征，如SuperPoint，或者是传统特征SIFT。假设图像<span
class="math inline">\(A,B\)</span>分别有<span
class="math inline">\(M,N\)</span>个特征，可以表示为<span
class="math inline">\(\mathcal{A}:=\{1, \ldots, M\}\)</span>以及<span
class="math inline">\(\mathcal{B}:=\{1, \ldots, N\}\)</span>。</p>
<p><strong>部分分配矩阵</strong>：约束i）和ii）意味着对应关系来自两组关键点之间的部分分配。我们给出一个软分配矩阵<span
class="math inline">\(\mathbf{P} \in[0,1]^{M \times
N}\)</span>，根据上述约束，我们有如下关系： <span
class="math display">\[
\mathbf{P} \mathbf{1}_{N} \leq \mathbf{1}_{M} \quad \text { and } \quad
\mathbf{P}^{\top} \mathbf{1}_{M} \leq \mathbf{1}_{N}
\]</span></p>
<p><img data-src="https://vincentqin.tech/blog-resources/superglue/superglue-ot-1.jpg" /></p>
<blockquote>
<p>为何上式中使用 "<span class="math inline">\(\leq\)</span>" 而非
"<span class="math inline">\(=\)</span>"？这里值得说明一下。</p>
</blockquote>
<p>首先要理解分配矩阵<span
class="math inline">\(\mathbf{P}\)</span>是什么。<span
class="math inline">\(\mathbf{P}\)</span>的每一行代表来自于图<span
class="math inline">\(A\)</span>中的某个特征点对应图<span
class="math inline">\(B\)</span>的<span
class="math inline">\(N\)</span>种匹配的可能性。如上图所示，图<span
class="math inline">\(A\)</span>有3个特征点，图<span
class="math inline">\(B\)</span>有4个特征点，那么这个分配矩阵的维度就是<span
class="math inline">\(\mathbf{P} \in \mathbb{R}^{3 \times
4}\)</span>。对于第0行，即图A的第0号特征点，它可能在图B中有4个匹配点，由上图种给出的软分配矩阵<span
class="math inline">\(\mathbf{P}\)</span>的第0行数据可以看到，最大是数字是0.6，即图<span
class="math inline">\(A\)</span>的第0号特征与图B的第1号特征是匹配的。相应的，对于<span
class="math inline">\(\mathbf{P}\)</span>的第0列，最大是数字是0.5，即图<span
class="math inline">\(B\)</span>的第0号特征与图<span
class="math inline">\(A\)</span>的第1号特征是匹配的，这看起来非常合理。</p>
<p>这里需要注意的是，这个<span
class="math inline">\(\mathbf{P}\)</span>是一个所谓的“软分配”矩阵，所以其中的元素并非是绝对的0或1。对于<span
class="math inline">\(\mathbf{P}\)</span>还需要满足规定：在理想情况下<span
class="math inline">\(\mathbf{P}\)</span>的行之和或者列之和等于1。此处的“理想情况”指的是图<span
class="math inline">\(A\)</span>与图<span
class="math inline">\(B\)</span>中的所有特征都可以在对方的图像上找到对应关系。但是实际情况下，可能存在遮挡/视角变化/检测噪声等因素的干扰，大概率会出现图<span
class="math inline">\(A\)</span>在图<span
class="math inline">\(B\)</span>中找不到对应的匹配点，反之亦然。</p>
<p><img data-src="https://vincentqin.tech/blog-resources/superglue/superglue-ot-2.jpg" /></p>
<p>如上图所示，对于<span
class="math inline">\(\mathbf{P}\)</span>的第3列，即图<span
class="math inline">\(B\)</span>的第3号特征而言，它并没有找到于其对应的特征匹配，所以对应的第3列之和是小于1的，确切来说对于一个调校的特别好的网络而言，第3列之和接近于0。</p>
<p>但是我们在做优化问题时并不喜欢不等于，所以作者后续对得分矩阵以及对应的分配矩阵进行了增广，让上述约束变成了<span
class="math inline">\(=\)</span>。具体地，我们放在<a
href="#遮挡以及可见性">遮挡以及可见性</a>进行解释。</p>
<p>那后续设计网络的最终目标就是解算构建一个代价矩阵并这个分配矩阵<span
class="math inline">\(\mathbf{P}\)</span>。</p>
<h3 id="注意力gnn">注意力GNN</h3>
<p>这里有个有意思的说法：特征点的位置以及视觉外观能够提高其特异性。另外一个具有启发性的观点是人类在寻找匹配点过程是具有参考价值的。想一下人类是怎样进行特征匹配的，人类通过来回浏览两个图像试探性筛选匹配关键点，并进行来回检查（如果不是匹配的特征，观察一下周围有没有匹配的更好的点，直到找到匹配点/或没有匹配）。上述过程人们通过主动寻找上下文来增加特征点特异性，这样可以排除一些具有奇异性的匹配。本文的核心就是利用基于注意力机制的GNN实现上述过程，即模拟了人类进行特征匹配。</p>
<h4 id="特征点encode">特征点Encode</h4>
<p>首先根据上述说法，特征点位置+描述会获得更强的特征匹配特异性，所以这里将特征点的位置以及描述子合并成每个特征点<span
class="math inline">\(i\)</span>的初始表示<span
class="math inline">\(^{(0)} \mathbf{x}_{i}\)</span>， <span
class="math display">\[
^{(0)} \mathbf{x}_{i}=\mathbf{d}_{i}+\mathbf{M L
P}_{\mathrm{enc}}\left(\mathbf{p}_{i}\right)
\]</span> 其中MLP表示多层感知机（Multilayer Perceptron
，MLP）此处用于对低维特征升维，上式实际上是将视觉外观以及特征点位置进行了耦合，正因如此，这使得该Encode形式使得后续的注意力机制能够充分考虑到特征的外观以及位置相似度。</p>
<p>特征点编码代码如下： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KeypointEncoder</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Joint encoding of visual appearance and location using MLPs&quot;&quot;&quot;</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; feature_dim: 256, layers: [32, 64, 128, 256]&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, feature_dim, layers</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.encoder = MLP([<span class="number">3</span>] + layers + [feature_dim]) <span class="comment"># MLP([3, 32, 64, 128, 256, 256])</span></span><br><span class="line">        nn.init.constant_(self.encoder[-<span class="number">1</span>].bias, <span class="number">0.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, kpts, scores</span>):</span><br><span class="line">        inputs = [kpts.transpose(<span class="number">1</span>, <span class="number">2</span>), scores.unsqueeze(<span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">return</span> self.encoder(torch.cat(inputs, dim=<span class="number">1</span>))    <span class="comment"># DIM: 1x256xM</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MLP</span>(<span class="params">channels: <span class="built_in">list</span>, do_bn=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Multi-layer perceptron &quot;&quot;&quot;</span></span><br><span class="line">    n = <span class="built_in">len</span>(channels)</span><br><span class="line">    layers = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">        layers.append(</span><br><span class="line">            nn.Conv1d(channels[i - <span class="number">1</span>], channels[i], kernel_size=<span class="number">1</span>, bias=<span class="literal">True</span>))</span><br><span class="line">        <span class="keyword">if</span> i &lt; (n-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> do_bn:</span><br><span class="line">                layers.append(nn.BatchNorm1d(channels[i]))</span><br><span class="line">            layers.append(nn.ReLU())</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)</span><br></pre></td></tr></table></figure>
将描述子与编码后的特征点相加可以得到后续多层GNN的输入的初值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Keypoint MLP encoder.</span></span><br><span class="line">desc0 = desc0 + self.kenc(kpts0, data[<span class="string">&#x27;scores0&#x27;</span>]) <span class="comment">#图A</span></span><br><span class="line">desc1 = desc1 + self.kenc(kpts1, data[<span class="string">&#x27;scores1&#x27;</span>]) <span class="comment">#图B</span></span><br></pre></td></tr></table></figure>
<h4 id="多层gnn">多层GNN</h4>
<p>考虑一个单一的完全图，它的节点是图像中每个特征点，这个图包括两种不同的无向边：一种是“Intra-image
edges”（self edge）<span class="math inline">\(\mathcal{E}_{\text {self
}}\)</span>，它连接了来自图像内部特征点；另外一种是“Inter-image
edges”（cross edge）<span class="math inline">\(\mathcal{E}_{\text
{cross }}\)</span>，它连接本图特征点<span
class="math inline">\(i\)</span>与另外一张图所有特征点（构成了该边）。</p>
<p>令<span class="math inline">\(^{(\ell)}
\mathbf{x}_{i}^{A}\)</span>表示为图像<span
class="math inline">\(A\)</span>上第<span
class="math inline">\(i\)</span>个元素在第<span
class="math inline">\(\ell\)</span>层的中间表达形式。信息（message）<span
class="math inline">\(\mathbf{m}_{\mathcal{E} \rightarrow
i}\)</span>是聚合了所有特征点<span class="math inline">\(\{j:(i, j) \in
\mathcal{E}\}\)</span>之后点结果（它的具体形式后面的Attentional
Aggregation会介绍，一句话来说就是将自我注意力以及交叉注意力进行聚合），其中<span
class="math inline">\(\mathcal{E} \in \{\mathcal{E}_{\text {self
}},\mathcal{E}_{\text {self }}\}\)</span>，所以图像<span
class="math inline">\(A\)</span>中所有特征<span
class="math inline">\(i\)</span>传递更新的残差信息（residual
message？）是： <span class="math display">\[
^{(\ell+1)} \mathbf{x}_{i}^{A}=^{(\ell)}
\mathbf{x}_{i}^{A}+\operatorname{MLP}\left(\left[^{(\ell)}
\mathbf{x}_{i}^{A} \| \mathbf{m}_{\mathcal{E} \rightarrow
i}\right]\right)
\]</span> 其中<span class="math inline">\([\cdot \|
\cdot]\)</span>表示串联操作。同样的，图像<span
class="math inline">\(B\)</span>上所有特征有类似的更新形式。可以看到self
以及cross
edges绑在一起并交替进行更新，先self后cross，作者提到共有固定数量的<span
class="math inline">\(L\)</span>层。</p>
<p>需要说明的是，这里的self-/cross-attention实际上就是模拟了人类来回浏览匹配的过程，其中self-attention是为了使得特征更加具有匹配特异性，而cross-attention是为了用这些具有特异性的点做图像间特征的相似度比较。</p>
<p>代码如下： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AttentionalGNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, feature_dim: <span class="built_in">int</span>, layer_names: <span class="built_in">list</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layers = nn.ModuleList([</span><br><span class="line">            AttentionalPropagation(feature_dim, <span class="number">4</span>)</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(layer_names))])</span><br><span class="line">        self.names = layer_names</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, desc0, desc1</span>):</span><br><span class="line">        <span class="keyword">for</span> layer, name <span class="keyword">in</span> <span class="built_in">zip</span>(self.layers, self.names):</span><br><span class="line">            layer.attn.prob = []</span><br><span class="line">            <span class="keyword">if</span> name == <span class="string">&#x27;cross&#x27;</span>:</span><br><span class="line">                src0, src1 = desc1, desc0</span><br><span class="line">            <span class="keyword">else</span>:  <span class="comment"># if name == &#x27;self&#x27;:</span></span><br><span class="line">                src0, src1 = desc0, desc1</span><br><span class="line">            delta0, delta1 = layer(desc0, src0), layer(desc1, src1)</span><br><span class="line">            desc0, desc1 = (desc0 + delta0), (desc1 + delta1)</span><br><span class="line">        <span class="keyword">return</span> desc0, desc1</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AttentionalPropagation</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, feature_dim: <span class="built_in">int</span>, num_heads: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.attn = MultiHeadedAttention(num_heads, feature_dim)</span><br><span class="line">        self.mlp = MLP([feature_dim*<span class="number">2</span>, feature_dim*<span class="number">2</span>, feature_dim]) <span class="comment">#其中MLP隐含层配置[512,512,256] </span></span><br><span class="line">        nn.init.constant_(self.mlp[-<span class="number">1</span>].bias, <span class="number">0.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, source</span>):</span><br><span class="line">        message = self.attn(x, source, source)           <span class="comment"># q,k,v, DIM: 1x256xM</span></span><br><span class="line">        <span class="keyword">return</span> self.mlp(torch.cat([x, message], dim=<span class="number">1</span>))  <span class="comment">#DIM: 1x256xM</span></span><br></pre></td></tr></table></figure></p>
<h4 id="attentional-aggregation">Attentional Aggregation</h4>
<p>这一小节介绍上述介绍种的message是如何获得的。</p>
<p>文章的亮点之一就是将注意力机制用于特征匹配，这到底是如何实现的呢？作者提到，注意力机制将self以及cross信息聚合得到<span
class="math inline">\(\mathbf{m}_{\mathcal{E} \rightarrow
i}\)</span>。其中self edge利用了self-attention[58]，cross
edge利用了cross-attention。类似于数据库检索，我们想要查询<span
class="math inline">\(\mathbf{q}_i\)</span>基于元素的属性即键<span
class="math inline">\(\mathbf{k}_i\)</span>，检索到了某些元素的值<span
class="math inline">\(\mathbf{v}_j\)</span>。 <span
class="math display">\[
\mathbf{m}_{\mathcal{E} \rightarrow i}=\sum_{j:(i, j) \in \mathcal{E}}
\alpha_{i j} \mathbf{v}_{j}
\]</span> 其中注意力权重<span
class="math inline">\({\alpha}_{ij}\)</span>是查询与检索到对象键值相似度的<span
class="math inline">\(\operatorname{Softmax}\)</span>即，<span
class="math inline">\(\alpha_{i
j}=\operatorname{Softmax}_{j}\left(\mathbf{q}_{i}^{\top}
\mathbf{k}_{j}\right)\)</span>。</p>
<p>这里需要解释一下键（key），query以及值（value）。令待查询点特征点<span
class="math inline">\(i\)</span>位于查询图像<span
class="math inline">\(Q\)</span>上，所有的源特征点位于图像<span
class="math inline">\(S\)</span>上，其中<span class="math inline">\((Q,
S) \in\{A,
B\}^{2}\)</span>，于是我们可以将key，query以及value写成下述形式： <span
class="math display">\[
\begin{aligned} \mathbf{q}_{i} &amp;=\mathbf{W}_{1}^{(\ell)}
\mathbf{x}_{i}^{Q}+\mathbf{b}_{1} \\\left[\begin{array}{l}\mathbf{k}_{j}
\\ \mathbf{v}_{j}\end{array}\right]
&amp;=\left[\begin{array}{l}\mathbf{W}_{2} \\
\mathbf{W}_{3}\end{array}\right](\ell)
\mathbf{x}_{i}^{S}+\left[\begin{array}{l}\mathbf{b}_{2} \\
\mathbf{b}_{3}\end{array}\right] \end{aligned}
\]</span> 每一层<span
class="math inline">\(\ell\)</span>都有其对应的一套投影参数，这些参数被所有的特征点共享。理解一下：此处的<span
class="math inline">\(\mathbf{q}_i\)</span>对应于待查询图像上某个特征点<span
class="math inline">\(i\)</span>的一种表示（self-attention映射），<span
class="math inline">\(\mathbf{k}_j\)</span>以及<span
class="math inline">\(\mathbf{v}_j\)</span>都是来自于召回的图像特征点<span
class="math inline">\(j\)</span>的一种表示（映射）；<span
class="math inline">\(\alpha_{i
j}\)</span>表示这两个特征相似度，它是由<span
class="math inline">\(\mathbf{q}_i\)</span>以及<span
class="math inline">\(\mathbf{k}_j\)</span>计算得到（在这里体现了cross-attention的思想？），越大就表示这两个特征越相似，然后利用该相似度对<span
class="math inline">\(\mathbf{v}_j\)</span>加权求和得到<span
class="math inline">\(\mathbf{m}_{\mathcal{E} \rightarrow
i}\)</span>，这就是所谓的<strong>特征聚合</strong>。</p>
<p>上面提到的这些概念有些难以理解，作者特意对上述过程进行了可视化，self-attention就是一张图像内部的边相连进行聚合，它能够更加关注具有特异性的所有点，且并不仅局限于其邻域位置特征（心心相依，何惧千里，逃...）；cross-attention做的就是匹配那些外观相似的两张图像见的特征。</p>
<figure>
<img data-src="https://vincentqin.tech/blog-resources/superglue/superglue_fig_4.png"
alt="superglue_fig_4" />
<figcaption aria-hidden="true">superglue_fig_4</figcaption>
</figure>
<figure>
<img data-src="https://vincentqin.tech/blog-resources/superglue/superglue_fig_7.jpg"
alt="superglue_fig_7" />
<figcaption aria-hidden="true">superglue_fig_7</figcaption>
</figure>
<p>下图展示了每层self-attention以及across-attention中权重<span
class="math inline">\({\alpha_{i
j}}\)</span>的结果。按照匹配从难到易，文中画出了3个不同的特征点作为演示，绿色特征点（容易），蓝色特征点（中等）以及红色特征点（困难）。对于self-attention，初始时它（某个特征）关联了图像上所有的点（首行），然后逐渐地关注在与该特征相邻近的特征点（尾行）。同样地，cross-attention主要关注去匹配可能的特征点，随着层的增加，它逐渐减少匹配点集直到收敛。绿色特征点在第9层就已经趋近收敛，而红色特征直到最后才能趋紧收敛（匹配）。可以看到无论是self还是cross，它们关注的区域都会随着网络层深度的增加而逐渐缩小。</p>
<figure>
<img data-src="https://vincentqin.tech/blog-resources/superglue/superglue_fig_15_1.jpg"
alt="superglue_fig_15" />
<figcaption aria-hidden="true">superglue_fig_15</figcaption>
</figure>
<p>经过了<span
class="math inline">\(L\)</span>次self/cross-attention后就可以得到注意力GNN的输出，对于图像<span
class="math inline">\(A\)</span>我们有： <span class="math display">\[
\mathbf{f}_{i}^{A}=\mathbf{W} \cdot^{(L)} \mathbf{x}_{i}^{A}+\mathbf{b},
\quad \forall i \in \mathcal{A}
\]</span> 我们可以把<span
class="math inline">\(\mathbf{f}_{i}^{A}\)</span>理解为<strong>匹配描述子</strong>（类比特征描述子），专门为特征匹配服务，对于图像<span
class="math inline">\(B\)</span>具有类似的形式。</p>
<h3 id="匹配层optimal-matching-layer">匹配层（Optimal matching
layer）</h3>
<p>接下来的任务就是去构建软分配矩阵<span
class="math inline">\(\mathbf{P}\)</span>。对于一般的图匹配流程，这个分配矩阵可以通过计算一个得分矩阵<span
class="math inline">\(\mathbf{S} \in \mathbb{R}^{M \times
N}\)</span>（用来表示一些潜在的匹配）来实现。具体而言，通过最大化总体得分<span
class="math inline">\(\sum_{i, j} \mathbf{S}_{i, j} \mathbf{P}_{i,
j}\)</span>即可得到这个分配矩阵<span
class="math inline">\(\mathbf{P}\)</span>，其中要注意的是<span
class="math inline">\(\mathbf{P}\)</span>是有约束的。</p>
<h4 id="匹配得分预测">匹配得分预测</h4>
<p><img data-src="https://vincentqin.tech/blog-resources/superglue/superglue-ot-sh-score.jpg" /></p>
<p>作者使用GNN聚合得到的<span
class="math inline">\(\mathbf{f}_{i}^{A}\)</span>以及<span
class="math inline">\(\mathbf{f}_{i}^{B}\)</span>计算内积得到得分：
<span class="math display">\[
\mathbf{S}_{i, j}=&lt;\mathbf{f}_{i}^{A}, \mathbf{f}_{j}^{B}&gt;,
\forall(i, j) \in \mathcal{A} \times \mathcal{B}
\]</span></p>
<h4 id="遮挡以及可见性">遮挡以及可见性</h4>
<p>类似于SuperPoint在提取特征点时增加了一层dustbin通道，专门为了应对图像中没有特征点情况。本文借鉴了该思想，在得分矩阵<span
class="math inline">\(\mathbf{S}\)</span>的最后一列/行设置为dustbins可以得到<span
class="math inline">\(\overline{\mathbf{S}}\)</span>，这样做的作用在于可以滤出错误的匹配点。
<span class="math display">\[
\overline{\mathbf{S}}_{i, N+1}=\overline{\mathbf{S}}_{M+1,
j}=\overline{\mathbf{S}}_{M+1, N+1}=z \in \mathbb{R}
\]</span> 图像<span
class="math inline">\(A\)</span>上的特征点被分配到图像<span
class="math inline">\(B\)</span>上某个特征匹配或者被分配到dustbin，这就意味着每个dustbin有<span
class="math inline">\(N,M\)</span>个匹配，因此软分配矩阵有如下约束：
<span class="math display">\[
\overline{\mathbf{P}} \mathbf{1}_{N+1}=\mathbf{a} \quad\text {  and }
\quad \overline{\mathbf{P}}^{\top} \mathbf{1}_{M+1}=\mathbf{b}
\]</span> 其中<span
class="math inline">\(\mathbf{a}=\left[\begin{array}{ll}\mathbf{1}_{M}^{\top}
&amp; N\end{array}\right]^{\top}\)</span>，<span
class="math inline">\(\mathbf{b}=\left[\begin{array}{ll}\mathbf{1}_{N}^{\top}
&amp; M\end{array}\right]^{\top}\)</span>。<span
class="math inline">\(\mathbf{a}\)</span> <strong>表示图<span
class="math inline">\(A\)</span>中特征点以及dustbin的期望匹配数</strong>，即正常情况下，图<span
class="math inline">\(A\)</span>中每个特征点在图<span
class="math inline">\(B\)</span>中仅且仅有1个匹配点，但是对于图<span
class="math inline">\(A\)</span>的dustbin而言，它可能匹配到图B的任何一个特征点，即有<span
class="math inline">\(N\)</span>种可能性，所以<span
class="math inline">\(\mathbf{a} =
\left[\begin{array}{ll}\mathbf{1}_{M}^{\top} &amp;
N\end{array}\right]^{\top}\)</span>。</p>
<p>作者Sarlin在这个<a
target="_blank" rel="noopener" href="https://github.com/magicleap/SuperGluePretrainedNetwork/issues/36">问题</a>中提到，上式的约束项之所以被替换成<span
class="math inline">\(=\)</span>，是因为做了类似于<code>松弛化</code>的操作，这么做的好处是将原本难以优化的不等问题变为恒等约束（原话为"These
are like slack variables that enforce the equality
constraint"），同时可以比较好的应对没有匹配的特征或者错误的特征（这其实是<strong>增加dustbin通道的原因，它起到滤除外点的作用</strong>）。</p>
<p><del>（<font color="red">此处不太理解，最后一维为何为N？</font>此处可参考<a
target="_blank" rel="noopener" href="https://blog.csdn.net/shizhuoduao/article/details/107120805">这篇文章</a>的解释。）</del></p>
<h4 id="sinkhorn-algorithm">Sinkhorn Algorithm</h4>
<p>求解最大化总体得分可由“Sinkhorn Algorithm”[52,12]进行求解。</p>
<p><img data-src="https://vincentqin.tech/blog-resources/superglue/superglue-ot-sh-1.png" /></p>
<p>此处有必要对optimal tranport问题做一下解释，有关optimal
tranport问题的介绍可参考这篇文章<a
target="_blank" rel="noopener" href="https://michielstock.github.io/posts/2017/2017-11-5-OptimalTransport/">Notes
on Optimal
Transport</a>。如上图所示，蓝色背景区域的几个公式给出了针对该特征匹配问题的“代价函数”，准确来说应该是<strong>负的代价函数</strong>。因为原始的最优传输问题中<span
class="math inline">\(\bar{S}\)</span>扮演的角色应该是<code>cost matrix</code>，即代价矩阵；对比之下，本例中<span
class="math inline">\(\bar{S}\)</span>为匹配描述子的余弦相似度，这正好与代价矩阵相反。正因如此，相较于原始最优传输问题的最小化代价函数，本例的目标是最大化匹配描述子的相似度，所以上式为<span
class="math inline">\(\max\)</span>而非<span
class="math inline">\(\min\)</span>。</p>
<p>至于如何求解最优传输问题，<code>sinkhorn algorithm</code>算法能够以一种迭代的方式对该问题进行求解，具体的方法是：
&gt; 给定：匹配描述子的余弦相似度矩阵<span
class="math inline">\(\bar{S}\)</span>，两个分布<span
class="math inline">\(\mathbf{a}\)</span>和<span
class="math inline">\(\mathbf{b}\)</span>，正则项<span
class="math inline">\(\lambda\)</span>（越大表示分配越均匀，默认为1）
初始化：分配矩阵：<span class="math inline">\(\mathbf{\bar{P}} =
\exp^{-\lambda \mathbf{\bar{S}}}\)</span> 重复：
1.缩放行，使得行之和为<span class="math inline">\(\mathbf{a}\)</span>.
2.缩放列，使得列之和为<span class="math inline">\(\mathbf{b}\)</span>.
直至收敛.</p>
<p>接下来，笔者给出一个简单的例子，一步步阐述<code>sinkhorn algorithm</code>是如何运作的。</p>
<p>首先给定输入，并初始化分配矩阵（注，为方便起见，分配矩阵被初始化为代价矩阵<span
class="math inline">\(\mathbf{\bar{P}}
=\mathbf{\bar{S}}\)</span>，实际情况下是<span
class="math inline">\(\mathbf{\bar{P}} = \exp^{-\lambda
\mathbf{\bar{S}}}\)</span>） <img data-src="https://vincentqin.tech/blog-resources/superglue/superglue-ot-sh-2.png" /></p>
<p>步骤1：计算目前的行之和；
步骤2：对于P矩阵的每一行，分别除以上述行之和并乘目标行之和a；</p>
<p><img data-src="https://vincentqin.tech/blog-resources/superglue/superglue-ot-sh-3.png" /></p>
<p>步骤3：计算目前的列之和；
步骤4：对于P矩阵的每一列，分别除以上述列之和并乘目标列之和b；</p>
<p><img data-src="https://vincentqin.tech/blog-resources/superglue/superglue-ot-sh-4.png" /></p>
<p>对行列重复执行1-4步，经过4次迭代后分配矩阵的行之和就与<span
class="math inline">\(\mathbf{a}\)</span>一致，列之和与<span
class="math inline">\(\mathbf{b}\)</span>一致。 <img data-src="https://vincentqin.tech/blog-resources/superglue/superglue-ot-sh-5.png" /></p>
<p>下面笔者使用matlab重写了一个<code>sinkhorn algorithm</code>的demo，感兴趣的同学可以运行一下，然后check下最后的分配矩阵P的行之和是否为1/列之和是否为1。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">clear all;</span><br><span class="line">close all;</span><br><span class="line">clc;</span><br><span class="line"></span><br><span class="line">lam = <span class="number">1</span>;</span><br><span class="line">epslion = <span class="number">1e-6</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% S_  = rand(3,4);</span></span><br><span class="line"></span><br><span class="line">S  = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>;</span><br><span class="line">         <span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>;</span><br><span class="line">         <span class="number">2</span>,<span class="number">6</span>,<span class="number">1</span>,<span class="number">3</span>];</span><br><span class="line"></span><br><span class="line">[m,n] = <span class="built_in">size</span>(S);</span><br><span class="line"></span><br><span class="line">a  = <span class="built_in">ones</span>(m,<span class="number">1</span>);</span><br><span class="line">b  = <span class="built_in">ones</span>(<span class="number">1</span>,n);</span><br><span class="line"></span><br><span class="line">[P_bar, error] = SinkhornAlgorithm(S,a,b,lam,epslion);</span><br><span class="line"></span><br><span class="line"><span class="built_in">figure</span>;</span><br><span class="line">axis equal</span><br><span class="line">imagesc(P_bar)</span><br><span class="line">set(gcf,<span class="string">&#x27;color&#x27;</span>,[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]);</span><br><span class="line">box off;</span><br><span class="line">axis off</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[P_bar, error]</span> = <span class="title">SinkhornAlgorithm</span><span class="params">(S,a,b,lam,epslion)</span></span></span><br><span class="line">    </span><br><span class="line"><span class="comment">%     Computes the optimal transport matrix and Slinkhorn distance using the</span></span><br><span class="line"><span class="comment">%     Sinkhorn-Knopp algorithm</span></span><br><span class="line"><span class="comment">% </span></span><br><span class="line"><span class="comment">%     Inputs:</span></span><br><span class="line"><span class="comment">%         - S : cost matrix (mxn)</span></span><br><span class="line"><span class="comment">%         - a: vector of marginals (m, )</span></span><br><span class="line"><span class="comment">%         - b : vector of marginals (n, )</span></span><br><span class="line"><span class="comment">%         - lam : strength of the entropic regularization</span></span><br><span class="line"><span class="comment">%         - epslion : convergence parameter</span></span><br><span class="line"><span class="comment">% </span></span><br><span class="line"><span class="comment">%     Outputs:</span></span><br><span class="line"><span class="comment">%         - P : optimal transport matrix (mxn)</span></span><br><span class="line"><span class="comment">%         - dist : Sinkhorn distance</span></span><br><span class="line"><span class="comment">%     Author: realcat </span></span><br><span class="line"><span class="comment">%     Date:    2022.04.03</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">% add dustbin channel</span></span><br><span class="line">  dust= <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line">  [m,n] = <span class="built_in">size</span>(S);</span><br><span class="line"></span><br><span class="line">  S_bar = [S,dust * <span class="built_in">ones</span>(m,<span class="number">1</span>);</span><br><span class="line">          dust *<span class="built_in">ones</span>(<span class="number">1</span>,n+<span class="number">1</span>)];</span><br><span class="line">    </span><br><span class="line">  a  = [a;n];</span><br><span class="line">  b  = [b,m];</span><br><span class="line"></span><br><span class="line">  <span class="comment">%% OT BEGIN</span></span><br><span class="line"></span><br><span class="line">  [m,n] = <span class="built_in">size</span>(S_bar);</span><br><span class="line">  P_bar = <span class="built_in">exp</span>(-lam * S_bar);</span><br><span class="line">  P_bar = P_bar / sum(P_bar(:));</span><br><span class="line"></span><br><span class="line">  max_iters = <span class="number">100</span>;</span><br><span class="line">  counter   = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> <span class="number">1</span></span><br><span class="line">    u     = sum(P_bar,<span class="number">2</span>);                 <span class="comment">% sum of rows</span></span><br><span class="line">    P_bar = P_bar .* <span class="built_in">repmat</span>(a./ u,[<span class="number">1</span>,n]); <span class="comment">% scale rows</span></span><br><span class="line">    v     = sum(P_bar,<span class="number">1</span>);                 <span class="comment">% sum of cols</span></span><br><span class="line">    P_bar = P_bar .* <span class="built_in">repmat</span>(b./ v,[m,<span class="number">1</span>]); <span class="comment">% scale cols</span></span><br><span class="line">    </span><br><span class="line">    error = <span class="built_in">max</span>((sum(P_bar,<span class="number">2</span>) - a));      <span class="comment">% check error</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">disp</span>([<span class="string">&#x27;error = &#x27;</span>, num2str(error)]);</span><br><span class="line">    <span class="keyword">if</span>(error &lt; epslion || counter &gt; max_iters)</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    counter = counter + <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span> <span class="comment">%end function</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>值得注意的是作者采用<strong>对数空间</strong>的<code>sinkhorn algorithm</code>算法，所以在完成算法迭代之后需要对<strong>结果进行指数运算才能得到分配矩阵</strong>。</p>
<p>作者Sarlin提供的代码如下： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">log_optimal_transport</span>(<span class="params">scores: torch.Tensor, alpha: torch.Tensor, iters: <span class="built_in">int</span></span>) -&gt; torch.Tensor:</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Perform Differentiable Optimal Transport in Log-space for stability&quot;&quot;&quot;</span></span><br><span class="line">    b, m, n = scores.shape</span><br><span class="line">    one = scores.new_tensor(<span class="number">1</span>)</span><br><span class="line">    ms, ns = (m*one).to(scores), (n*one).to(scores)</span><br><span class="line"></span><br><span class="line">    bins0 = alpha.expand(b, m, <span class="number">1</span>)</span><br><span class="line">    bins1 = alpha.expand(b, <span class="number">1</span>, n)</span><br><span class="line">    alpha = alpha.expand(b, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    couplings = torch.cat([torch.cat([scores, bins0], -<span class="number">1</span>),</span><br><span class="line">                           torch.cat([bins1, alpha], -<span class="number">1</span>)], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    norm = - (ms + ns).log()</span><br><span class="line">    log_mu = torch.cat([norm.expand(m), ns.log()[<span class="literal">None</span>] + norm])</span><br><span class="line">    log_nu = torch.cat([norm.expand(n), ms.log()[<span class="literal">None</span>] + norm])</span><br><span class="line">    log_mu, log_nu = log_mu[<span class="literal">None</span>].expand(b, -<span class="number">1</span>), log_nu[<span class="literal">None</span>].expand(b, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    Z = log_sinkhorn_iterations(couplings, log_mu, log_nu, iters)</span><br><span class="line">    Z = Z - norm  <span class="comment"># multiply probabilities by M+N</span></span><br><span class="line">    <span class="keyword">return</span> Z</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">log_sinkhorn_iterations</span>(<span class="params">Z, log_mu, log_nu, iters: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Perform Sinkhorn Normalization in Log-space for stability&quot;&quot;&quot;</span></span><br><span class="line">    u, v = torch.zeros_like(log_mu), torch.zeros_like(log_nu)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(iters):</span><br><span class="line">        u = log_mu - torch.logsumexp(Z + v.unsqueeze(<span class="number">1</span>), dim=<span class="number">2</span>)</span><br><span class="line">        v = log_nu - torch.logsumexp(Z + u.unsqueeze(<span class="number">2</span>), dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> Z + u.unsqueeze(<span class="number">2</span>) + v.unsqueeze(<span class="number">1</span>)    </span><br></pre></td></tr></table></figure></p>
<h3 id="loss">Loss</h3>
<p>GNN网络以及最优匹配层都是可微的，这使得反向传播训练成为可能。网络训练使用了一种监督学习的方式，即有了匹配的真值<span
class="math inline">\(\mathcal{M}=\{(i, j)\} \subset \mathcal{A} \times
\mathcal{B}\)</span>（如，由真值相对位姿变换得到的匹配关系），当然也可以获得一些没有匹配的特征点<span
class="math inline">\(\mathcal{I} \subseteq \mathcal{A}\)</span>以及$
<span
class="math inline">\(。当给定真值标签，就可以去最小化分配矩阵\)</span>$
负对数似然函数： <span class="math display">\[
\begin{aligned} \operatorname{Loss}=&amp;-\sum_{(i, j) \in \mathcal{M}}
\log \overline{\mathbf{P}}_{i, j} \\ &amp;-\sum_{i \in \mathcal{I}} \log
\overline{\mathbf{P}}_{i, N+1}-\sum_{j \in \mathcal{J}} \log
\overline{\mathbf{P}}_{M+1, j} \end{aligned}
\]</span>
这个监督学习的目标是同时最大化精度以及匹配的召回率，接下来的训练过程略过，直接开始实验阶段的介绍。</p>
<h2 id="实验">实验</h2>
<p>特征匹配的目的是为了解算出两帧之间的相对位姿，所以实验对比的一个指标就是<strong>单应矩阵</strong>估计，另外还有室内外的位姿估计。只能说SuperGlue的效果太好了，直接放结果吧（本来论文7页就写完了，作者放了10页附录大招）。</p>
<h3 id="单应矩阵估计">单应矩阵估计</h3>
<p>能够获得非常高的匹配召回率（98.3%）同时获得超高的精度，比传统的暴力匹配都好了一大截。</p>
<figure>
<img data-src="https://vincentqin.tech/blog-resources/superglue/superglue_tb_1.png"
alt="superglue_tb_1" />
<figcaption aria-hidden="true">superglue_tb_1</figcaption>
</figure>
<h3 id="室内外位姿估计">室内外位姿估计</h3>
<p>下表看来，大基线室内位姿估计也是相当棒，完胜传统算法。</p>
<figure>
<img data-src="https://vincentqin.tech/blog-resources/superglue/superglue_tb_2.png"
alt="superglue_tb_2" />
<figcaption aria-hidden="true">superglue_tb_2</figcaption>
</figure>
<figure>
<img data-src="https://vincentqin.tech/blog-resources/superglue/superglue_tb_3.png"
alt="superglue_tb_3" />
<figcaption aria-hidden="true">superglue_tb_3</figcaption>
</figure>
<h3 id="网络耗时">网络耗时</h3>
<p>接下来放出大家比较关心的网络耗时，下图是在NVIDIA GeForce GTX 1080
GPU跑了500次的结果，512个点69ms（14.5fps），1024个点87ms（11.5fps）。</p>
<figure>
<img data-src="https://vincentqin.tech/blog-resources/superglue/superglue_fig_11.png"
alt="superglue_tb_3" />
<figcaption aria-hidden="true">superglue_tb_3</figcaption>
</figure>
<h3 id="更多匹配结果">更多匹配结果</h3>
<p>第一列是SuperPoint+暴力匹配结果，第二列是SuperPoint+OAnet（ICCV
2019）结果，第三列是SuperPoint+SuperGlue结果。能看到SuperGlue惊人的特征匹配能力，尤其是在大视角变化时优势明显（红线表示错误匹配，绿线表示正确匹配）。</p>
<p><img data-src="https://vincentqin.tech/blog-resources/superglue/superglue_res_3.jpg" /></p>
<p><img data-src="https://vincentqin.tech/blog-resources/superglue/superglue_res_1.jpg" /></p>
<p><img data-src="https://vincentqin.tech/blog-resources/superglue/superglue_res_2.jpg" /></p>
<h2 id="结论">结论</h2>
<p>本文展示了基于注意力的图神经网络对局部特征匹配的强大功能。
SuperGlue的框架使用两种注意力：（i）自我注意力，可以增强局部描述符的接受力；以及（ii）交叉注意力，可以实现跨图像交流，并受到人类来回观察方式的启发进行匹配图像。文中方法通过解决<strong>最优运输问题</strong>，优雅地处理了特征分配问题以及遮挡点。实验表明，SuperGlue与现有方法相比有了显着改进，可以在极宽的基线室内和室外图像对上进行高精度的相对姿势估计。此外，SuperGlue可以实时运行，并且可以同时使用经典和深度学习特征。</p>
<p>总而言之，论文提出的可学习的中后端（middle-end）算法以功能强大的神经网络模型替代了手工启发式技术，该模型同时在单个统一体系结构中执行上下文聚合，匹配和过滤外点。作者最后提到：若与深度学习前端结合使用，SuperGlue是迈向端到端深度学习SLAM的重要里程碑。（when
combined with a deep front-end, SuperGlue is a major milestone towards
end-to-end deep SLAM）</p>
<p>这真是鼓舞SLAM研究人员的士气！</p>
<p>顺便给个SuperGlue代码的流程框图：</p>
<p><img data-src="https://vincentqin.tech/blog-resources/superglue/superglue-workflow.jpg" /></p>
<h2 id="改进点-update-2022.05.17">改进点 (Update: 2022.05.17)</h2>
<p>主要从<strong>改进特征编码形式，attention形式，改进最优传输问题的求解策略</strong>等角度进行展开。</p>
<ul>
<li><p><strong>A Unified Framework for Implicit Sinkhorn
Differentiation</strong>，CVPR
2022，，分析了深度学习中任务中通用<code>Sinkhorn</code>层的隐含梯度的使用，文中指出SuperGlue中使用的是自动微分的<code>sinkhorn algorithm</code>，收敛速度可能较慢且容易出现OOM，而本算法能够解决该问题(不过并没有进行验证)
** [<a
target="_blank" rel="noopener" href="https://github.com/marvin-eisenberger/implicit-sinkhorn">Code</a>]**</p></li>
<li><p><strong>OpenGlue - Open Source Pipeline for Image
Matching</strong>，arXiv
2022，复现了SuperGlue，包括训练以及推理过程，OpenGlue对基于图的匹配过程进行概况，形成了一套易替换和后续开发的模块和流程；此外基于上述流程对SuperGlue中attention等步骤进行改进；开源协议有更新，OpenGlue可商用
** [<a target="_blank" rel="noopener" href="https://github.com/ucuapps/OpenGlue">Code</a>]**</p></li>
<li><p><strong>MatchFormer: Interleaving Attention in Transformers for
Feature Matching</strong>，arXiv 2022，改进的LoFTR，
将attention引入特征编码阶段，大幅度提升特征匹配在大视角变化时的匹配性能
** [<a
target="_blank" rel="noopener" href="https://github.com/jamycheung/MatchFormer">Code</a>]**</p></li>
<li><p><strong>LoFTR: Detector-Free Local Feature Matching with
Transformers</strong>, CVPR 2021，无特征匹配，匹配性能强劲 <strong>[<a
target="_blank" rel="noopener" href="https://github.com/zju3dv/LoFTR">Code</a>]</strong></p></li>
<li><p><strong>valgur/SuperGluePretrainedNetwork</strong>, 实现了 C++
调用 SuperGlue：包含使用 <a
target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.jit.script.html">jit
scripts</a> 将SuperPoint以及SuperGlue序列化，然后使用pytorch的 C++
接口进行调用 <strong>[<a
target="_blank" rel="noopener" href="https://github.com/valgur/SuperGluePretrainedNetwork">Code</a>]</strong></p></li>
<li><p><strong>SuperGlue with Physarum Dynamics</strong>,
最优传输问题的求解由Sinkhorn Algorithm 替换成 <a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2004.14539">Physarum Dynamics solver</a>
<strong>[<a
target="_blank" rel="noopener" href="https://github.com/HeatherJiaZG/Superglue-with-Physarum-Dynamics">Code</a>]</strong></p></li>
<li><p><strong>Superglue-Jittor</strong>，改进了图注意力机制中矩阵运算，采用分块优化的方式进行，降低了匹配过程中的显存占用；使用<code>dual-Softmax</code>
替换 <code>sinkhorn algorithm</code> <strong>[<a
target="_blank" rel="noopener" href="https://github.com/smy-THU/superglue-jittor">Code</a>]</strong></p></li>
<li><p><strong>SuperGlue PyTorch
Implementation</strong>，pytorch复现SuperGlue <strong>[<a
target="_blank" rel="noopener" href="https://github.com/HeatherJiaZG/SuperGlue-pytorch">Code</a>]</strong></p></li>
<li><p><strong>MNNSuperGlue</strong>，MNN Superglue 关键点匹配C++实现
<strong>[<a
target="_blank" rel="noopener" href="https://github.com/Hanson0910/MNNSuperGlue">Code</a>]</strong></p></li>
</ul>
<h2 id="参考">参考</h2>
<ul>
<li><a
target="_blank" rel="noopener" href="https://github.com/magicleap/SuperGluePretrainedNetwork">SuperGlue
源码</a></li>
<li><a target="_blank" rel="noopener" href="http://xxx.itp.ac.cn/pdf/1911.11763v2">SuperGlue
Paper</a></li>
<li><a target="_blank" rel="noopener" href="https://image-matching-workshop.github.io/">Image Matching:
Local Features &amp; Beyond CVPR 2020 Workshop</a></li>
<li><a
target="_blank" rel="noopener" href="http://huitaofuwu.com/2020/08/19/%E5%88%9D%E6%8E%A2GNN-SuperGLue%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">初探GNN&amp;SuperGLue阅读笔记</a></li>
<li><a
target="_blank" rel="noopener" href="https://blog.csdn.net/shizhuoduao/article/details/107120805">SuperGlue:Learning
Feature Matching with Graph Neural Networks 解读与实验</a></li>
</ul>
<!-- ---

![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_01.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_02.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_03.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_04.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_05.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_06.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_07.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_08.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_09.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_10.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_11.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_12.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_13.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_14.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_15.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_16.png)
![](https://gitee.com/vincentqin/BlogResource-5/raw/master/superglue/superglue_paper/SuperGlue.pdf_page_17.png) -->

    </div>

    
    
    
      


    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>Vincent Qin
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://www.vincentqin.tech/posts/superglue/" title="📝笔记：SuperGlue:Learning Feature Matching with Graph Neural Networks论文阅读">https://www.vincentqin.tech/posts/superglue/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/SLAM/" rel="tag"># SLAM</a>
              <a href="/tags/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/" rel="tag"># 特征提取</a>
              <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
              <a href="/tags/%E7%AC%94%E8%AE%B0/" rel="tag"># 笔记</a>
              <a href="/tags/%E8%AE%BA%E6%96%87/" rel="tag"># 论文</a>
              <a href="/tags/SuperGlue/" rel="tag"># SuperGlue</a>
              <a href="/tags/MagicLeap/" rel="tag"># MagicLeap</a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/slam-common-issues-SVD/" rel="prev" title="📝笔记：SLAM常见问题(五)：Singular Value Decomposition（SVD）分解">
                  <i class="fa fa-chevron-left"></i> 📝笔记：SLAM常见问题(五)：Singular Value Decomposition（SVD）分解
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/posts/2020-image-matching-cvpr/" rel="next" title="📝笔记：CVPR2020图像匹配挑战赛，新数据集+新评测方法，SOTA正瑟瑟发抖！">
                  📝笔记：CVPR2020图像匹配挑战赛，新数据集+新评测方法，SOTA正瑟瑟发抖！ <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="waline"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2016 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Vincent Qin</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/next-boot.js"></script>

  

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.8/pdfobject.min.js","integrity":"sha256-tu9j5pBilBQrWSDePOOajCUdz6hWsid/lBNzK4KgEPM="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.1.6/mermaid.min.js","integrity":"sha256-ZfzwelSToHk5YAcr9wbXAmWgyn9Jyq08fSLrLhZE89w="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>



  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="waline" type="application/json">{"lang":"en-US","enable":true,"serverURL":"https://comments.vincentqin.tech","cssUrl":"https://unpkg.com/@waline/client@v2/dist/waline.css","commentCount":true,"pageview":true,"locale":{"placeholder":"Welcome to comment"},"emoji":["https://unpkg.com/@waline/emojis@1.1.0/weibo","https://unpkg.com/@waline/emojis@1.1.0/alus","https://unpkg.com/@waline/emojis@1.1.0/bilibili","https://unpkg.com/@waline/emojis@1.1.0/qq","https://unpkg.com/@waline/emojis@1.1.0/tieba","https://unpkg.com/@waline/emojis@1.1.0/tw-emoji"],"meta":["nick","mail","link"],"requiredMeta":["nick","mail"],"wordLimit":0,"login":"enable","el":"#waline","comment":true,"libUrl":"//unpkg.com/@waline/client@v2/dist/waline.js","path":"/posts/superglue/"}</script>
<link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>

</body>
</html>
